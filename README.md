<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚   â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—       â”‚
â”‚   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•       â”‚
â”‚   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘            â”‚
â”‚   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘            â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—       â”‚
â”‚   â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•      â”‚
â”‚                                                                  â”‚
â”‚        2D LiDAR Point Cloud Completion Â· Deep Learning          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<br>

[![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-EE4C2C?style=flat-square&logo=pytorch&logoColor=white)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-Research-22C55E?style=flat-square)](#)
[![Status](https://img.shields.io/badge/Status-Active-F59E0B?style=flat-square)](#)

<br>

**Comparative study of Conv and Diffusion models for structured 1D geometric completion.**  
Given partial 360Â° LiDAR scans with missing regions, reconstruct the complete scan.

<br>

</div>

---

## ğŸ”¬ Research Questions

This project rigorously investigates four questions:

| # | Research Question |
|---|---|
| **RQ1** | How strong is a simple Conv U-Net baseline for 2D LiDAR completion? |
| **RQ2** | Does replacing zero-filled missing regions with **random noise** improve Conv baselines? |
| **RQ3** | Can conditional diffusion models **outperform** Conv baselines on this task? |
| **RQ4** | Which design choices (conditioning strategy, time embedding, residual blocks) are **necessary** for diffusion models to become competitive? |

> All models share the same dataset, input representation (partial + mask), evaluation protocol, and statistical tests â€” ensuring fair comparison.

---

## ğŸ—ï¸ Models

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model            â”‚ Description                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv(zero)       â”‚ 1D Conv U-Net Â· missing regions â†’ filled with zeros       â”‚
â”‚ Conv(noise)      â”‚ 1D Conv U-Net Â· missing regions â†’ filled with Gaussian Îµ  â”‚
â”‚ Diffusion v1     â”‚ Conditional DDPM Â· masked diffusion with Conv U-Net       â”‚
â”‚ Diffusion v2     â”‚ Dual-Encoder DDPM Â· FiLM time conditioning + ResBlocks    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Repository Structure

```
diffusion_completion/
â”œâ”€â”€ baseline/                  â† Conv(zero) and Conv(noise)
â”‚   â”œâ”€â”€ model.py               Â· LiDARCompletionModel (1D Conv U-Net)
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ visualize.py
â”‚
â”œâ”€â”€ diffusion/                 â† Diffusion v1  (Conditional DDPM)
â”‚   â”œâ”€â”€ model.py               Â· ConditionalDDPMUNet  (~4â€“5M params)
â”‚   â”œâ”€â”€ noise_scheduler.py     Â· Linear Î² schedule, T=100
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ sample.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ visualize.py
â”‚
â”œâ”€â”€ diffusion_v2/              â† Diffusion v2  (Dual Encoder + FiLM + ResBlocks)
â”‚   â”œâ”€â”€ model.py               Â· DualEncoderDDPMUNet
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ sample.py
â”‚
â”œâ”€â”€ generate_dataset.py        â† Synthetic 2D LiDAR dataset generator
â”œâ”€â”€ statistical_test.py        â† Paired t-test Â· Wilcoxon Â· Cohen's d
â”œâ”€â”€ run_experiments.sh         â† Full pipeline  (train â†’ eval â†’ stats)
â””â”€â”€ requirements.txt
```

---

## ğŸ—ƒï¸ Dataset Generation

Synthetic 2D LiDAR scans are generated as triplets:

```
partial  â†’  corrupted scan with missing regions
mask     â†’  binary mask  (1 = observed,  0 = missing)
target   â†’  complete ground-truth scan
```

```bash
python generate_dataset.py
```

**Outputs:**
- `output/train`, `output/val`
- `output_validation/train`, `output_validation/val`

---

## ğŸš€ Training

### Conv(zero) / Conv(noise)

```bash
cd baseline

python train.py \
  --train_dirs ../output/train ../output_validation/train \
  --val_dirs   ../output/val   ../output_validation/val   \
  --fill_mode  zero \                # or: noise
  --experiment_name conv_zero_seed42 \
  --output_dir ./experiments \
  --epochs 100 --batch_size 64 --lr 1e-3 --seed 42 --device cuda
```

### Diffusion v1

```bash
cd diffusion

python train.py \
  --train_dirs ../output/train ../output_validation/train \
  --val_dirs   ../output/val   ../output_validation/val   \
  --experiment_name diffusion_seed42 \
  --output_dir ./experiments \
  --epochs 100 --batch_size 64 --lr 2e-4 --T 100 --seed 42 --device cuda
```

### Diffusion v2 â€” Dual Encoder + FiLM

```bash
cd diffusion_v2

python train.py \
  --train_dirs ../output/train ../output_validation/train \
  --val_dirs   ../output/val   ../output_validation/val   \
  --experiment_name diffusion_v2_seed42 \
  --output_dir ./experiments \
  --epochs 100 --batch_size 64 --lr 2e-4 --T 100 \
  --base_channels 64 --num_res_blocks 2 \
  --seed 42 --device cuda
```

> âš ï¸ Each model is trained with **three random seeds** (42, 43, 44) to ensure statistical reliability.

---

## ğŸ“Š Evaluation & Statistical Testing

```bash
python statistical_test.py \
  --zero_fill_dirs      results/eval/conv_zero_seed42  results/eval/conv_zero_seed43  results/eval/conv_zero_seed44  \
  --noise_fill_dirs     results/eval/conv_noise_seed42 results/eval/conv_noise_seed43 results/eval/conv_noise_seed44 \
  --diffusion_dirs      results/eval/diffusion_seed42  results/eval/diffusion_seed43  results/eval/diffusion_seed44  \
  --diffusion_v2_dirs   results/eval/diffusion_v2_seed42 results/eval/diffusion_v2_seed43 results/eval/diffusion_v2_seed44 \
  --output_dir results/statistical_tests \
  --seeds 42 43 44
```

**Applied tests:**

| Test | Purpose |
|------|---------|
| Paired t-test | Mean difference significance |
| Wilcoxon signed-rank | Non-parametric robustness check |
| Cohen's *d* | Effect size estimation |

---

## ğŸ§  Diffusion v2 Architecture

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚              DualEncoderDDPMUNet             â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  INPUT (partial, mask)                    INPUT (x_t, mask)
        â”‚                                        â”‚
        â–¼                                        â–¼
  obs_encoder                             noisy_encoder
  2ch â†’ ch â†’ 2ch â†’ 4ch                   2ch â†’ ch â†’ 2ch â†’ 4ch
  (no skip connections)                  (skip connections â†’ decoder)
        â”‚                                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
              Bottleneck: cat(obs, noisy) = 8ch
                       â”‚
              FiLMResBlocks  â† time embedding
                       â”‚
                      4ch
                       â”‚
                  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Decoder  (with noisy_encoder skips)    â”‚
                  â”‚  up(4ch) + skip(4ch) â†’ 4ch              â”‚
                  â”‚  up(4ch) + skip(2ch) â†’ 2ch              â”‚
                  â”‚  up(2ch) + skip(ch)  â†’ ch               â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
              GN â†’ SiLU â†’ Conv1d(châ†’1)
                       â”‚
                       â–¼
                  Output: (B, 360)
```

---

## ğŸ“ˆ Key Findings

> Results reflect current experimental status.

- **Conv(zero)** is a surprisingly strong baseline â€” the 1D inductive bias for local continuity is very effective.
- **Conv(noise)** slightly improves robustness to missing regions compared to zero-fill.
- **Diffusion v1** underperforms Conv baselines â€” naÃ¯ve conditional DDPM is insufficient for this structured signal.
- **Diffusion v2** improves stability and conditioning quality, but still struggles on **sharp geometric transitions** (corners, doorways).

---

## ğŸ”­ Future Directions

- [ ] **Structured noise design** â€” geometry-aware local/smooth noise tailored to LiDAR
- [ ] **Cross-attention** between observed and missing regions
- [ ] **Faster sampling** via DDIM or flow matching
- [ ] **Hybrid Conv + Diffusion** architectures
- [ ] **Geometric priors** â€” ray continuity constraints, wall regularity

---

## ğŸ“„ License

This repository is intended for **research and experimental purposes**.  
Feel free to adapt the codebase for LiDAR completion or related sensor reconstruction tasks.

---

<div align="center">

*2D LiDAR Point Cloud Completion â€” Bridging structured sensor completion and generative modeling.*

</div>
